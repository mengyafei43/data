{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "BASE_WORK_PATH = \"/home/myn1szh/AI_2021/sign-plate-detection/\"\n",
    "with open(BASE_WORK_PATH + \"sign-plate-detection_train.json\") as jf:\n",
    "    train_ds = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dataset...\n",
      "[INFO] saving testing filenames...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading dataset...\")\n",
    "\n",
    "data = []\n",
    "targets = []\n",
    "filenames = []\n",
    "# loop over the row\n",
    "for i in range(len(train_ds[\"annotations\"])):\n",
    "    image_name = train_ds[\"images\"][train_ds[\"annotations\"][i][\"image_id\"]][\"file_name\"]\n",
    "    filename = BASE_WORK_PATH + \"images/\" + image_name\n",
    "    h = 200\n",
    "    w = 200\n",
    "    startX = train_ds[\"annotations\"][i][\"bbox\"][0]\n",
    "    startY = train_ds[\"annotations\"][i][\"bbox\"][1]\n",
    "    endX = startX + train_ds[\"annotations\"][i][\"bbox\"][2]\n",
    "    endY = startY + train_ds[\"annotations\"][i][\"bbox\"][3]\n",
    "    # scale the bounding box coordinates relative to the spatial\n",
    "    # dimensions of the input image\n",
    "    startX = float(startX)/w\n",
    "    startY = float(startY) / h\n",
    "    endX = float(endX) / w\n",
    "    endY = float(endY) / h\n",
    "    # load the image and preprocess it\n",
    "    image = load_img(filename, target_size=(200, 200))\n",
    "    image = img_to_array(image)\n",
    "    # update our list of data, targets, and filenames\n",
    "    data.append(image)\n",
    "    targets.append((startX, startY, endX, endY))\n",
    "    filenames.append(filename)\n",
    "    # convert the data and targets to NumPy arrays, scaling the input\n",
    "# pixel intensities from the range [0, 255] to [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "targets = np.array(targets, dtype=\"float32\")\n",
    "# partition the data into training and testing splits using 90% of\n",
    "# the data for training and the remaining 10% for testing\n",
    "split = train_test_split(data, targets, filenames, test_size=0.10,random_state=42)\n",
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "(trainFilenames, testFilenames) = split[4:]\n",
    "# write the testing filenames to disk so that we can use then\n",
    "# when evaluating/testing our bounding box regressor\n",
    "print(\"[INFO] saving testing filenames...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layers are left off\n",
    "#vgg = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(200, 200, 3)))\n",
    "vgg = VGG16(weights=\"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n",
    "            include_top=False,input_tensor=Input(shape=(200, 200, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all VGG layers so they will *not* be updated during the\n",
    "# training process\n",
    "vgg.trainable = False\n",
    "# flatten the max-pooling output of VGG\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "# construct a fully-connected layer header to output the predicted\n",
    "# bounding box coordinates\n",
    "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
    "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "bbox_head = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
    "bbox_probs = Dense(1, activation=\"softmax\")(bboxHead)\n",
    "# construct the model we will fine-tune for bounding box regression\n",
    "model = Model(inputs=vgg.input, outputs=[bbox_probs,bbox_head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 200, 200, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 200, 200, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 100, 100, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 100, 100, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 100, 100, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 50, 50, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 50, 50, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 50, 50, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 50, 50, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 25, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 25, 25, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 25, 25, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 25, 25, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 12, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 12, 12, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 12, 12, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 12, 12, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 18432)        0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          2359424     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            33          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            132         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,084,613\n",
      "Trainable params: 2,369,925\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer, compile the model, and show the model\n",
    "# summary\n",
    "INIT_LR = 1e-4\n",
    "opt = Adam(lr=INIT_LR)\n",
    "model.compile(loss=\"mse\", optimizer=opt)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training bounding box regressor...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'google.protobuf.pyext._message.FieldProperty' object has no attribute 'allow_growth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fa6eb77f38df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mseesion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mINIT_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'google.protobuf.pyext._message.FieldProperty' object has no attribute 'allow_growth'"
     ]
    }
   ],
   "source": [
    "# train the network for bounding box regression\n",
    "print(\"[INFO] training bounding box regressor...\")\n",
    "\"\"\"\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto\n",
    "config.gpu_options.allow_growth = True\n",
    "seesion=InteractiveSession(config=config)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "H = model.fit(\n",
    "    trainImages, trainTargets,\n",
    "    validation_data=(testImages, testTargets),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving object detector model...\")\n",
    "model.save(\"test.h5\", save_format=\"h5\")\n",
    "# plot the model training history\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our trained bounding box regressor from disk\n",
    "print(\"[INFO] loading object detector...\")\n",
    "model = load_model(config.MODEL_PATH)\n",
    "# loop over the images that we'll be testing using our bounding box\n",
    "# regression model\n",
    "for imagePath in imagePaths:\n",
    "\t# load the input image (in Keras format) from disk and preprocess\n",
    "\t# it, scaling the pixel intensities to the range [0, 1]\n",
    "\timage = load_img(imagePath, target_size=(200, 200))\n",
    "\timage = img_to_array(image) / 255.0\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "    \t# make bounding box predictions on the input image\n",
    "\tpreds = model.predict(image)[0]\n",
    "\t(probs, startX, startY, endX, endY) = preds\n",
    "\t# load the input image (in OpenCV format), resize it such that it\n",
    "\t# fits on our screen, and grab its dimensions\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = imutils.resize(image, width=600)\n",
    "\t(h, w) = image.shape[:2]\n",
    "\t# scale the predicted bounding box coordinates based on the image\n",
    "\t# dimensions\n",
    "\tstartX = int(startX * w)\n",
    "\tstartY = int(startY * h)\n",
    "\tendX = int(endX * w)\n",
    "\tendY = int(endY * h)\n",
    "\t# draw the predicted bounding box on the image\n",
    "\tcv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "\t\t(0, 255, 0), 2)\n",
    "\t# show the output image\n",
    "\tcv2.imshow(\"Output\", image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
